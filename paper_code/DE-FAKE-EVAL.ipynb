{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"T4","authorship_tag":"ABX9TyOAc8u5lP2Ao1n2AJZAaBCh"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","source":["# SETUP"],"metadata":{"id":"gtjSKlKHCjbb"}},{"cell_type":"code","execution_count":20,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":73},"id":"N1RIgqStCXrB","executionInfo":{"status":"ok","timestamp":1738702959638,"user_tz":300,"elapsed":4407703,"user":{"displayName":"Rohan Wagh","userId":"06660321697866433484"}},"outputId":"a435e2ad-a296-4a99-dbf0-09b2d19ca4eb"},"outputs":[{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","     <input type=\"file\" id=\"files-46386065-acb2-41f9-a026-b6e2cb4e63f3\" name=\"files[]\" multiple disabled\n","        style=\"border:none\" />\n","     <output id=\"result-46386065-acb2-41f9-a026-b6e2cb4e63f3\">\n","      Upload widget is only available when the cell has been executed in the\n","      current browser session. Please rerun this cell to enable.\n","      </output>\n","      <script>// Copyright 2017 Google LLC\n","//\n","// Licensed under the Apache License, Version 2.0 (the \"License\");\n","// you may not use this file except in compliance with the License.\n","// You may obtain a copy of the License at\n","//\n","//      http://www.apache.org/licenses/LICENSE-2.0\n","//\n","// Unless required by applicable law or agreed to in writing, software\n","// distributed under the License is distributed on an \"AS IS\" BASIS,\n","// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n","// See the License for the specific language governing permissions and\n","// limitations under the License.\n","\n","/**\n"," * @fileoverview Helpers for google.colab Python module.\n"," */\n","(function(scope) {\n","function span(text, styleAttributes = {}) {\n","  const element = document.createElement('span');\n","  element.textContent = text;\n","  for (const key of Object.keys(styleAttributes)) {\n","    element.style[key] = styleAttributes[key];\n","  }\n","  return element;\n","}\n","\n","// Max number of bytes which will be uploaded at a time.\n","const MAX_PAYLOAD_SIZE = 100 * 1024;\n","\n","function _uploadFiles(inputId, outputId) {\n","  const steps = uploadFilesStep(inputId, outputId);\n","  const outputElement = document.getElementById(outputId);\n","  // Cache steps on the outputElement to make it available for the next call\n","  // to uploadFilesContinue from Python.\n","  outputElement.steps = steps;\n","\n","  return _uploadFilesContinue(outputId);\n","}\n","\n","// This is roughly an async generator (not supported in the browser yet),\n","// where there are multiple asynchronous steps and the Python side is going\n","// to poll for completion of each step.\n","// This uses a Promise to block the python side on completion of each step,\n","// then passes the result of the previous step as the input to the next step.\n","function _uploadFilesContinue(outputId) {\n","  const outputElement = document.getElementById(outputId);\n","  const steps = outputElement.steps;\n","\n","  const next = steps.next(outputElement.lastPromiseValue);\n","  return Promise.resolve(next.value.promise).then((value) => {\n","    // Cache the last promise value to make it available to the next\n","    // step of the generator.\n","    outputElement.lastPromiseValue = value;\n","    return next.value.response;\n","  });\n","}\n","\n","/**\n"," * Generator function which is called between each async step of the upload\n"," * process.\n"," * @param {string} inputId Element ID of the input file picker element.\n"," * @param {string} outputId Element ID of the output display.\n"," * @return {!Iterable<!Object>} Iterable of next steps.\n"," */\n","function* uploadFilesStep(inputId, outputId) {\n","  const inputElement = document.getElementById(inputId);\n","  inputElement.disabled = false;\n","\n","  const outputElement = document.getElementById(outputId);\n","  outputElement.innerHTML = '';\n","\n","  const pickedPromise = new Promise((resolve) => {\n","    inputElement.addEventListener('change', (e) => {\n","      resolve(e.target.files);\n","    });\n","  });\n","\n","  const cancel = document.createElement('button');\n","  inputElement.parentElement.appendChild(cancel);\n","  cancel.textContent = 'Cancel upload';\n","  const cancelPromise = new Promise((resolve) => {\n","    cancel.onclick = () => {\n","      resolve(null);\n","    };\n","  });\n","\n","  // Wait for the user to pick the files.\n","  const files = yield {\n","    promise: Promise.race([pickedPromise, cancelPromise]),\n","    response: {\n","      action: 'starting',\n","    }\n","  };\n","\n","  cancel.remove();\n","\n","  // Disable the input element since further picks are not allowed.\n","  inputElement.disabled = true;\n","\n","  if (!files) {\n","    return {\n","      response: {\n","        action: 'complete',\n","      }\n","    };\n","  }\n","\n","  for (const file of files) {\n","    const li = document.createElement('li');\n","    li.append(span(file.name, {fontWeight: 'bold'}));\n","    li.append(span(\n","        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n","        `last modified: ${\n","            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n","                                    'n/a'} - `));\n","    const percent = span('0% done');\n","    li.appendChild(percent);\n","\n","    outputElement.appendChild(li);\n","\n","    const fileDataPromise = new Promise((resolve) => {\n","      const reader = new FileReader();\n","      reader.onload = (e) => {\n","        resolve(e.target.result);\n","      };\n","      reader.readAsArrayBuffer(file);\n","    });\n","    // Wait for the data to be ready.\n","    let fileData = yield {\n","      promise: fileDataPromise,\n","      response: {\n","        action: 'continue',\n","      }\n","    };\n","\n","    // Use a chunked sending to avoid message size limits. See b/62115660.\n","    let position = 0;\n","    do {\n","      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n","      const chunk = new Uint8Array(fileData, position, length);\n","      position += length;\n","\n","      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n","      yield {\n","        response: {\n","          action: 'append',\n","          file: file.name,\n","          data: base64,\n","        },\n","      };\n","\n","      let percentDone = fileData.byteLength === 0 ?\n","          100 :\n","          Math.round((position / fileData.byteLength) * 100);\n","      percent.textContent = `${percentDone}% done`;\n","\n","    } while (position < fileData.byteLength);\n","  }\n","\n","  // All done.\n","  yield {\n","    response: {\n","      action: 'complete',\n","    }\n","  };\n","}\n","\n","scope.google = scope.google || {};\n","scope.google.colab = scope.google.colab || {};\n","scope.google.colab._files = {\n","  _uploadFiles,\n","  _uploadFilesContinue,\n","};\n","})(self);\n","</script> "]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Saving data.zip to data.zip\n"]}],"source":["import zipfile\n","import os\n","from google.colab import files\n","\n","uploaded = files.upload() #BEWARE WILL TAKE LIKE AN HOUR\n","# Unzip the data\n","with zipfile.ZipFile(\"/content/data.zip\", 'r') as zip_ref:\n","    zip_ref.extractall(\"/content/data\")"]},{"cell_type":"code","source":["!git clone https://github.com/zeyangsha/De-Fake.git"],"metadata":{"id":"dlIhuQs9EgSv","executionInfo":{"status":"ok","timestamp":1738702980370,"user_tz":300,"elapsed":1607,"user":{"displayName":"Rohan Wagh","userId":"06660321697866433484"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"b9a2a3d7-0ae9-49ac-a72c-14a22a6a1a33"},"execution_count":21,"outputs":[{"output_type":"stream","name":"stdout","text":["Cloning into 'De-Fake'...\n","remote: Enumerating objects: 91, done.\u001b[K\n","remote: Counting objects: 100% (91/91), done.\u001b[K\n","remote: Compressing objects: 100% (82/82), done.\u001b[K\n","remote: Total 91 (delta 37), reused 17 (delta 3), pack-reused 0 (from 0)\u001b[K\n","Receiving objects: 100% (91/91), 72.64 KiB | 12.11 MiB/s, done.\n","Resolving deltas: 100% (37/37), done.\n"]}]},{"cell_type":"code","source":["!pip install git+https://github.com/openai/CLIP.git"],"metadata":{"id":"ml8rVot9Enya","executionInfo":{"status":"ok","timestamp":1738703084292,"user_tz":300,"elapsed":99541,"user":{"displayName":"Rohan Wagh","userId":"06660321697866433484"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"7b0c3b1a-2b31-49fc-9d84-b67f5df36551"},"execution_count":22,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting git+https://github.com/openai/CLIP.git\n","  Cloning https://github.com/openai/CLIP.git to /tmp/pip-req-build-_r07uhh7\n","  Running command git clone --filter=blob:none --quiet https://github.com/openai/CLIP.git /tmp/pip-req-build-_r07uhh7\n","  Resolved https://github.com/openai/CLIP.git to commit dcba3cb2e2827b402d2701e7e1c7d9fed8a20ef1\n","  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","Collecting ftfy (from clip==1.0)\n","  Downloading ftfy-6.3.1-py3-none-any.whl.metadata (7.3 kB)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from clip==1.0) (24.2)\n","Requirement already satisfied: regex in /usr/local/lib/python3.11/dist-packages (from clip==1.0) (2024.11.6)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from clip==1.0) (4.67.1)\n","Requirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (from clip==1.0) (2.5.1+cu124)\n","Requirement already satisfied: torchvision in /usr/local/lib/python3.11/dist-packages (from clip==1.0) (0.20.1+cu124)\n","Requirement already satisfied: wcwidth in /usr/local/lib/python3.11/dist-packages (from ftfy->clip==1.0) (0.2.13)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch->clip==1.0) (3.17.0)\n","Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.11/dist-packages (from torch->clip==1.0) (4.12.2)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch->clip==1.0) (3.4.2)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch->clip==1.0) (3.1.5)\n","Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch->clip==1.0) (2024.10.0)\n","Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch->clip==1.0)\n","  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n","Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch->clip==1.0)\n","  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n","Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch->clip==1.0)\n","  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n","Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch->clip==1.0)\n","  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n","Collecting nvidia-cublas-cu12==12.4.5.8 (from torch->clip==1.0)\n","  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n","Collecting nvidia-cufft-cu12==11.2.1.3 (from torch->clip==1.0)\n","  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n","Collecting nvidia-curand-cu12==10.3.5.147 (from torch->clip==1.0)\n","  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n","Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch->clip==1.0)\n","  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n","Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch->clip==1.0)\n","  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n","Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch->clip==1.0) (2.21.5)\n","Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch->clip==1.0) (12.4.127)\n","Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch->clip==1.0)\n","  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n","Requirement already satisfied: triton==3.1.0 in /usr/local/lib/python3.11/dist-packages (from torch->clip==1.0) (3.1.0)\n","Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch->clip==1.0) (1.13.1)\n","Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch->clip==1.0) (1.3.0)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from torchvision->clip==1.0) (1.26.4)\n","Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.11/dist-packages (from torchvision->clip==1.0) (11.1.0)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch->clip==1.0) (3.0.2)\n","Downloading ftfy-6.3.1-py3-none-any.whl (44 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.8/44.8 kB\u001b[0m \u001b[31m4.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m4.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m114.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m78.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m61.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m5.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m12.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m7.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m6.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m67.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hBuilding wheels for collected packages: clip\n","  Building wheel for clip (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for clip: filename=clip-1.0-py3-none-any.whl size=1369489 sha256=b687bb035111a41ade3c81a3e11e5c1d661738851f0d6ac831bedaa237fe59be\n","  Stored in directory: /tmp/pip-ephem-wheel-cache-nisykttd/wheels/3f/7c/a4/9b490845988bf7a4db33674d52f709f088f64392063872eb9a\n","Successfully built clip\n","Installing collected packages: nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, ftfy, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, clip\n","  Attempting uninstall: nvidia-nvjitlink-cu12\n","    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\n","    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\n","      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\n","  Attempting uninstall: nvidia-curand-cu12\n","    Found existing installation: nvidia-curand-cu12 10.3.6.82\n","    Uninstalling nvidia-curand-cu12-10.3.6.82:\n","      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n","  Attempting uninstall: nvidia-cufft-cu12\n","    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n","    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n","      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n","  Attempting uninstall: nvidia-cuda-runtime-cu12\n","    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n","    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n","      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n","  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n","    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n","    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n","      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n","  Attempting uninstall: nvidia-cuda-cupti-cu12\n","    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n","    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n","      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n","  Attempting uninstall: nvidia-cublas-cu12\n","    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n","    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n","      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n","  Attempting uninstall: nvidia-cusparse-cu12\n","    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n","    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n","      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n","  Attempting uninstall: nvidia-cudnn-cu12\n","    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n","    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n","      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n","  Attempting uninstall: nvidia-cusolver-cu12\n","    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n","    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n","      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\n","Successfully installed clip-1.0 ftfy-6.3.1 nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127\n"]}]},{"cell_type":"code","source":["!pip install fairscale\n","!pip install torch torchvision --no-cache-dir\n","!pip install -q condacolab\n","import condacolab\n","condacolab.install()\n","!pip install numpy==1.23.5 --force-reinstall"],"metadata":{"id":"WNadBxz8EpQJ","executionInfo":{"status":"ok","timestamp":1738703171706,"user_tz":300,"elapsed":13810,"user":{"displayName":"Rohan Wagh","userId":"06660321697866433484"}},"colab":{"base_uri":"https://localhost:8080/","height":1000},"outputId":"af4ebab4-2366-4f1e-b7a6-7b942a03be04"},"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: fairscale in /usr/local/lib/python3.11/dist-packages (0.4.13)\n","Requirement already satisfied: torch>=1.8.0 in /usr/local/lib/python3.11/dist-packages (from fairscale) (2.5.1+cu124)\n","Requirement already satisfied: numpy>=1.22.0 in /usr/local/lib/python3.11/dist-packages (from fairscale) (1.23.5)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->fairscale) (3.17.0)\n","Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->fairscale) (4.12.2)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->fairscale) (3.4.2)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->fairscale) (3.1.5)\n","Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->fairscale) (2024.10.0)\n","Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->fairscale) (12.4.127)\n","Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->fairscale) (12.4.127)\n","Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->fairscale) (12.4.127)\n","Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->fairscale) (9.1.0.70)\n","Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->fairscale) (12.4.5.8)\n","Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->fairscale) (11.2.1.3)\n","Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->fairscale) (10.3.5.147)\n","Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->fairscale) (11.6.1.9)\n","Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->fairscale) (12.3.1.170)\n","Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->fairscale) (2.21.5)\n","Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->fairscale) (12.4.127)\n","Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->fairscale) (12.4.127)\n","Requirement already satisfied: triton==3.1.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->fairscale) (3.1.0)\n","Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->fairscale) (1.13.1)\n","Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>=1.8.0->fairscale) (1.3.0)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=1.8.0->fairscale) (3.0.2)\n","Requirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (2.5.1+cu124)\n","Requirement already satisfied: torchvision in /usr/local/lib/python3.11/dist-packages (0.20.1+cu124)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch) (3.17.0)\n","Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.11/dist-packages (from torch) (4.12.2)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch) (3.4.2)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch) (3.1.5)\n","Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch) (2024.10.0)\n","Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n","Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n","Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n","Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch) (9.1.0.70)\n","Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.5.8)\n","Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch) (11.2.1.3)\n","Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch) (10.3.5.147)\n","Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch) (11.6.1.9)\n","Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch) (12.3.1.170)\n","Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch) (2.21.5)\n","Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n","Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n","Requirement already satisfied: triton==3.1.0 in /usr/local/lib/python3.11/dist-packages (from torch) (3.1.0)\n","Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch) (1.13.1)\n","Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch) (1.3.0)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from torchvision) (1.23.5)\n","Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.11/dist-packages (from torchvision) (11.1.0)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch) (3.0.2)\n","Collecting numpy==1.23.5\n","  Using cached numpy-1.23.5-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (2.3 kB)\n","Using cached numpy-1.23.5-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (17.1 MB)\n","Installing collected packages: numpy\n","  Attempting uninstall: numpy\n","    Found existing installation: numpy 1.23.5\n","    Uninstalling numpy-1.23.5:\n","      Successfully uninstalled numpy-1.23.5\n","\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","albucore 0.0.19 requires numpy>=1.24.4, but you have numpy 1.23.5 which is incompatible.\n","jaxlib 0.4.33 requires numpy>=1.24, but you have numpy 1.23.5 which is incompatible.\n","jax 0.4.33 requires numpy>=1.24, but you have numpy 1.23.5 which is incompatible.\n","scikit-image 0.25.1 requires numpy>=1.24, but you have numpy 1.23.5 which is incompatible.\n","imbalanced-learn 0.13.0 requires numpy<3,>=1.24.3, but you have numpy 1.23.5 which is incompatible.\n","blosc2 3.0.0 requires numpy>=1.25.0, but you have numpy 1.23.5 which is incompatible.\n","chex 0.1.88 requires numpy>=1.24.1, but you have numpy 1.23.5 which is incompatible.\n","albumentations 1.4.20 requires numpy>=1.24.4, but you have numpy 1.23.5 which is incompatible.\n","tensorflow 2.18.0 requires numpy<2.1.0,>=1.26.0, but you have numpy 1.23.5 which is incompatible.\n","pymc 5.19.1 requires numpy>=1.25.0, but you have numpy 1.23.5 which is incompatible.\n","xarray 2025.1.1 requires numpy>=1.24, but you have numpy 1.23.5 which is incompatible.\n","bigframes 1.34.0 requires numpy>=1.24.0, but you have numpy 1.23.5 which is incompatible.\u001b[0m\u001b[31m\n","\u001b[0mSuccessfully installed numpy-1.23.5\n"]},{"output_type":"display_data","data":{"application/vnd.colab-display-data+json":{"pip_warning":{"packages":["numpy"]},"id":"7be668f802e7476bbcc0f43b9a61470f"}},"metadata":{}}]},{"cell_type":"code","source":["%cd De-Fake\n","!mamba env create -f environment.yaml"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Sbp8jwYTErSp","executionInfo":{"status":"ok","timestamp":1738703524548,"user_tz":300,"elapsed":303854,"user":{"displayName":"Rohan Wagh","userId":"06660321697866433484"}},"outputId":"53f148f9-64b9-458e-ea02-f88a01386a6a"},"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["/content/De-Fake\n","Channels:\n"," - pytorch\n"," - defaults\n"," - conda-forge\n","Platform: linux-64\n","Collecting package metadata (repodata.json): - \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\bdone\n","Solving environment: / \b\b- \b\bdone\n","\n","\n","==> WARNING: A newer version of conda exists. <==\n","    current version: 24.11.2\n","    latest version: 25.1.1\n","\n","Please update conda by running\n","\n","    $ conda update -n base -c conda-forge conda\n","\n","\n","\n","Downloading and Extracting Packages:\n","pytorch-1.12.1       | 1.19 GB   | :   0% 0/1 [00:00<?, ?it/s]\n","cudatoolkit-11.3.1   | 549.3 MB  | :   0% 0/1 [00:00<?, ?it/s]\u001b[A\n","\n","mkl-2021.4.0         | 142.6 MB  | :   0% 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A\n","\n","\n","python-3.8.5         | 49.3 MB   | :   0% 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","torchvision-0.13.1   | 28.7 MB   | :   0% 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","\n","ffmpeg-4.3           | 9.9 MB    | :   0% 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","\n","\n","numpy-base-1.23.1    | 5.6 MB    | :   0% 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","\n","\n","\n","libgcc-ng-11.2.0     | 5.3 MB    | :   0% 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","\n","\n","\n","\n","libstdcxx-ng-11.2.0  | 4.7 MB    | :   0% 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","\n","\n","\n","\n","\n","intel-openmp-2021.4. | 4.2 MB    | :   0% 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","openssl-1.1.1w       | 3.7 MB    | :   0% 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","tk-8.6.14            | 3.4 MB    | :   0% 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","pip-20.3.3           | 1.8 MB    | :   0% 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","setuptools-75.1.0    | 1.7 MB    | :   0% 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","sqlite-3.45.3        | 1.2 MB    | :   0% 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","gnutls-3.6.15        | 1.0 MB    | :   0% 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","ncurses-6.4          | 914 KB    | :   0% 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","nettle-3.7.3         | 809 KB    | :   0% 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","pillow-10.4.0        | 795 KB    | :   0% 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","pytorch-1.12.1       | 1.19 GB   | :   0% 0.0002940192716886597/1 [00:00<05:40, 340.22s/it]\n","\n","mkl-2021.4.0         | 142.6 MB  | :   3% 0.02706079342966272/1 [00:00<00:03,  3.70s/it]\u001b[A\u001b[A\n","\n","\n","python-3.8.5         | 49.3 MB   | :   8% 0.07926678226405746/1 [00:00<00:01,  1.27s/it]\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","pytorch-1.12.1       | 1.19 GB   | :   0% 0.0043080215025686226/1 [00:00<00:40, 40.32s/it] \n","\n","mkl-2021.4.0         | 142.6 MB  | :   6% 0.06442002646413636/1 [00:00<00:02,  3.03s/it]\u001b[A\u001b[A\n","\n","\n","python-3.8.5         | 49.3 MB   | :  18% 0.1772405251424325/1 [00:00<00:00,  1.11s/it] \u001b[A\u001b[A\u001b[A\n","\n","\n","\n","pytorch-1.12.1       | 1.19 GB   | :   1% 0.008194189267496994/1 [00:00<00:31, 32.07s/it] \n","\n","\n","python-3.8.5         | 49.3 MB   | :  27% 0.26950705969779537/1 [00:00<00:00,  1.10s/it]\u001b[A\u001b[A\u001b[A\n","\n","mkl-2021.4.0         | 142.6 MB  | :  10% 0.09750650264129483/1 [00:00<00:02,  3.11s/it]\u001b[A\u001b[A\n","\n","\n","\n","pytorch-1.12.1       | 1.19 GB   | :   1% 0.012374376304114025/1 [00:00<00:27, 28.27s/it]\n","\n","\n","python-3.8.5         | 49.3 MB   | :  38% 0.3776269507059698/1 [00:00<00:00,  1.03s/it] \u001b[A\u001b[A\u001b[A\n","\n","mkl-2021.4.0         | 142.6 MB  | :  13% 0.129716515873363/1 [00:00<00:02,  3.16s/it]  \u001b[A\u001b[A\n","\n","\n","\n","pytorch-1.12.1       | 1.19 GB   | :   2% 0.01592817445756826/1 [00:00<00:27, 28.32s/it] \n","cudatoolkit-11.3.1   | 549.3 MB  | :   0% 2.8446521484989748e-05/1 [00:00<4:53:43, 17624.48s/it]\u001b[A\n","\n","\n","python-3.8.5         | 49.3 MB   | :  48% 0.4752836264552886/1 [00:00<00:00,  1.05s/it]\u001b[A\u001b[A\u001b[A\n","\n","mkl-2021.4.0         | 142.6 MB  | :  16% 0.16367945499561176/1 [00:00<00:02,  3.08s/it]\u001b[A\u001b[A\n","\n","\n","\n","pytorch-1.12.1       | 1.19 GB   | :   2% 0.020338463532898154/1 [00:00<00:26, 26.59s/it]\n","\n","\n","python-3.8.5         | 49.3 MB   | :  59% 0.5910131285608125/1 [00:00<00:00,  1.02it/s]\u001b[A\u001b[A\u001b[A\n","\n","mkl-2021.4.0         | 142.6 MB  | :  20% 0.20005266721685883/1 [00:00<00:02,  3.02s/it]\u001b[A\u001b[A\n","cudatoolkit-11.3.1   | 549.3 MB  | :   0% 0.00011378608593995899/1 [00:00<1:19:21, 4762.43s/it] \u001b[A\n","\n","\n","\n","pytorch-1.12.1       | 1.19 GB   | :   2% 0.024096796831874934/1 [00:00<00:26, 27.01s/it]\n","\n","\n","python-3.8.5         | 49.3 MB   | :  70% 0.6956452811493683/1 [00:00<00:00,  1.02it/s]\u001b[A\u001b[A\u001b[A\n","\n","mkl-2021.4.0         | 142.6 MB  | :  23% 0.2339060484709713/1 [00:00<00:02,  3.04s/it] \u001b[A\u001b[A\n","pytorch-1.12.1       | 1.19 GB   | :   3% 0.027803996344471078/1 [00:00<00:26, 27.32s/it]\n","\n","\n","python-3.8.5         | 49.3 MB   | :  80% 0.7980579638345305/1 [00:00<00:00,  1.01it/s]\u001b[A\u001b[A\u001b[A\n","\n","mkl-2021.4.0         | 142.6 MB  | :  27% 0.26688296677999346/1 [00:00<00:02,  3.20s/it]\u001b[A\u001b[A\n","cudatoolkit-11.3.1   | 549.3 MB  | :   0% 0.0004835908652448257/1 [00:00<18:38, 1118.69s/it] \u001b[A\n","\n","\n","pytorch-1.12.1       | 1.19 GB   | :   3% 0.031472845517281745/1 [00:00<00:27, 28.43s/it]\n","\n","mkl-2021.4.0         | 142.6 MB  | :  30% 0.29832607493510765/1 [00:00<00:02,  3.20s/it]\u001b[A\u001b[A\n","pytorch-1.12.1       | 1.19 GB   | :   4% 0.03597261871877776/1 [00:01<00:25, 26.50s/it] \n","\n","mkl-2021.4.0         | 142.6 MB  | :  34% 0.3395198333543513/1 [00:01<00:01,  2.93s/it] \u001b[A\u001b[A\n","pytorch-1.12.1       | 1.19 GB   | :   4% 0.03978208580413517/1 [00:01<00:25, 26.90s/it]\n","\n","mkl-2021.4.0         | 142.6 MB  | :  37% 0.37392100394914524/1 [00:01<00:01,  3.01s/it]\u001b[A\u001b[A\n","cudatoolkit-11.3.1   | 549.3 MB  | :   0% 0.001450772595734477/1 [00:01<06:48, 409.13s/it] \u001b[A\n","\n","\n","\n","pytorch-1.12.1       | 1.19 GB   | :   4% 0.043514852209921635/1 [00:01<00:26, 27.62s/it]\n","\n","mkl-2021.4.0         | 142.6 MB  | :  41% 0.41226625779684545/1 [00:01<00:01,  2.88s/it]\u001b[A\u001b[A\n","\n","\n","\n","\n","ffmpeg-4.3           | 9.9 MB    | :   0% 0.0015713236502815128/1 [00:01<13:00, 781.95s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n","pytorch-1.12.1       | 1.19 GB   | :   5% 0.04714535104294682/1 [00:01<00:26, 28.27s/it] \n","\n","\n","\n","\n","ffmpeg-4.3           | 9.9 MB    | :  37% 0.367689734165874/1 [00:01<00:01,  2.63s/it]     \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n","cudatoolkit-11.3.1   | 549.3 MB  | :   0% 0.0027593125840440053/1 [00:01<03:49, 230.10s/it]\u001b[A\n","\n","mkl-2021.4.0         | 142.6 MB  | :  45% 0.44721521773232076/1 [00:01<00:01,  3.31s/it]\u001b[A\u001b[A\n","\n","\n","\n","\n","pytorch-1.12.1       | 1.19 GB   | :   5% 0.050699149196401054/1 [00:01<00:28, 30.12s/it]\n","cudatoolkit-11.3.1   | 549.3 MB  | :   0% 0.0038687269219586057/1 [00:01<02:40, 160.87s/it]\u001b[A\n","\n","pytorch-1.12.1       | 1.19 GB   | :   5% 0.05404841220433274/1 [00:01<00:29, 31.08s/it] \n","cudatoolkit-11.3.1   | 549.3 MB  | :   1% 0.005262606474723103/1 [00:01<01:59, 120.16s/it] \u001b[A\n","\n","pytorch-1.12.1       | 1.19 GB   | :   6% 0.05729540763950316/1 [00:01<00:29, 31.80s/it]\n","cudatoolkit-11.3.1   | 549.3 MB  | :   1% 0.007196969935702406/1 [00:01<01:26, 87.55s/it] \u001b[A\n","\n","pytorch-1.12.1       | 1.19 GB   | :   6% 0.06070858788041064/1 [00:01<00:29, 31.54s/it]\n","cudatoolkit-11.3.1   | 549.3 MB  | :   1% 0.009700263826381504/1 [00:01<01:05, 66.33s/it]\u001b[A\n","\n","mkl-2021.4.0         | 142.6 MB  | :  57% 0.5749596919792306/1 [00:01<00:01,  3.51s/it]\u001b[A\u001b[A\n","cudatoolkit-11.3.1   | 549.3 MB  | :   1% 0.013227632490520232/1 [00:01<00:47, 47.96s/it]\u001b[A\n","\n","\n","\n","\n","ffmpeg-4.3           | 9.9 MB    | : 100% 1.0/1 [00:01<00:00,  1.37s/it]               \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","\n","pytorch-1.12.1       | 1.19 GB   | :   6% 0.06389166608260527/1 [00:01<00:34, 37.15s/it]\n","pytorch-1.12.1       | 1.19 GB   | :   7% 0.06670402433354027/1 [00:02<00:34, 37.27s/it]\n","\n","mkl-2021.4.0         | 142.6 MB  | :  60% 0.6037734112990739/1 [00:02<00:01,  4.88s/it]\u001b[A\u001b[A\n","pytorch-1.12.1       | 1.19 GB   | :   7% 0.0694780322446898/1 [00:02<00:35, 38.22s/it] \n","\n","mkl-2021.4.0         | 142.6 MB  | :  63% 0.6300672996517827/1 [00:02<00:01,  4.75s/it]\u001b[A\u001b[A\n","pytorch-1.12.1       | 1.19 GB   | :   7% 0.07252049253433766/1 [00:02<00:36, 39.09s/it]\n","\n","mkl-2021.4.0         | 142.6 MB  | :  66% 0.6621677550157146/1 [00:02<00:01,  4.25s/it]\u001b[A\u001b[A\n","pytorch-1.12.1       | 1.19 GB   | :   8% 0.07512831563975013/1 [00:02<00:36, 39.17s/it]\n","\n","mkl-2021.4.0         | 142.6 MB  | :  69% 0.6881329697640144/1 [00:02<00:01,  4.18s/it]\u001b[A\u001b[A\n","pytorch-1.12.1       | 1.19 GB   | :   8% 0.07772335529856743/1 [00:02<00:36, 39.46s/it]\n","cudatoolkit-11.3.1   | 549.3 MB  | :   4% 0.04451880612400896/1 [00:02<00:18, 19.59s/it] \u001b[A\n","\n","mkl-2021.4.0         | 142.6 MB  | :  71% 0.7137695109079054/1 [00:02<00:01,  4.36s/it]\u001b[A\u001b[A\n","\n","\n","\n","\n","\n","numpy-base-1.23.1    | 5.6 MB    | :   0% 0.002780831476079401/1 [00:02<15:11, 914.45s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","pytorch-1.12.1       | 1.19 GB   | :   8% 0.08035674529717021/1 [00:02<00:36, 39.45s/it]\n","cudatoolkit-11.3.1   | 549.3 MB  | :   5% 0.051488203887831444/1 [00:02<00:16, 17.71s/it]\u001b[A\n","\n","\n","\n","\n","\n","\n","libgcc-ng-11.2.0     | 5.3 MB    | :   0% 0.002924573701970517/1 [00:02<14:52, 895.59s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","pytorch-1.12.1       | 1.19 GB   | :   8% 0.0832969380140568/1 [00:02<00:35, 38.72s/it] \n","cudatoolkit-11.3.1   | 549.3 MB  | :   6% 0.05717750818482939/1 [00:02<00:16, 17.67s/it] \u001b[A\n","\n","mkl-2021.4.0         | 142.6 MB  | :  76% 0.7619749728878714/1 [00:02<00:01,  4.39s/it]\u001b[A\u001b[A\n","\n","\n","\n","\n","\n","\n","libgcc-ng-11.2.0     | 5.3 MB    | :  78% 0.7837857521280986/1 [00:02<00:00,  2.49s/it]   \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","\n","\n","pytorch-1.12.1       | 1.19 GB   | :   9% 0.08603259558542085/1 [00:02<00:35, 38.60s/it]\n","cudatoolkit-11.3.1   | 549.3 MB  | :   6% 0.06323661726113221/1 [00:02<00:16, 17.57s/it]\u001b[A\n","\n","mkl-2021.4.0         | 142.6 MB  | :  79% 0.7854203566690366/1 [00:02<00:00,  4.43s/it]\u001b[A\u001b[A\n","\n","\n","\n","\n","\n","pytorch-1.12.1       | 1.19 GB   | :   9% 0.08864041869083332/1 [00:02<00:35, 38.71s/it]\n","cudatoolkit-11.3.1   | 549.3 MB  | :   7% 0.06895436807961515/1 [00:02<00:16, 18.15s/it]\u001b[A\n","\n","mkl-2021.4.0         | 142.6 MB  | :  81% 0.8084275089776568/1 [00:02<00:00,  4.71s/it]\u001b[A\u001b[A\n","\n","\n","\n","\n","\n","\n","libgcc-ng-11.2.0     | 5.3 MB    | : 100% 1.0/1 [00:02<00:00,  2.49s/it]               \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","\n","\n","numpy-base-1.23.1    | 5.6 MB    | :   4% 0.04449330361727041/1 [00:02<00:34, 36.25s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","\n","\n","\n","\n","pytorch-1.12.1       | 1.19 GB   | :   9% 0.09123545834965062/1 [00:03<00:36, 39.88s/it]\n","cudatoolkit-11.3.1   | 549.3 MB  | :   8% 0.07532638889225285/1 [00:03<00:16, 17.67s/it]\u001b[A\n","\n","mkl-2021.4.0         | 142.6 MB  | :  83% 0.8301199668686414/1 [00:03<00:00,  5.09s/it]\u001b[A\u001b[A\n","\n","\n","\n","\n","\n","numpy-base-1.23.1    | 5.6 MB    | :   7% 0.06673995542590562/1 [00:03<00:19, 21.11s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","\n","\n","\n","\n","libstdcxx-ng-11.2.0  | 4.7 MB    | :  43% 0.4295855520248003/1 [00:03<00:02,  5.18s/it]   \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","\n","\n","pytorch-1.12.1       | 1.19 GB   | :   9% 0.09375379732889697/1 [00:03<00:54, 59.86s/it]\n","\n","\n","\n","\n","\n","numpy-base-1.23.1    | 5.6 MB    | :  13% 0.12791824789965245/1 [00:03<00:07,  8.65s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","\n","\n","numpy-base-1.23.1    | 5.6 MB    | :  16% 0.16128822561260525/1 [00:03<00:05,  6.52s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n","cudatoolkit-11.3.1   | 549.3 MB  | :   8% 0.0810156931892508/1 [00:03<00:32, 35.60s/it] \u001b[A\n","\n","\n","\n","\n","\n","numpy-base-1.23.1    | 5.6 MB    | :  19% 0.19187737184947867/1 [00:03<00:04,  5.45s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","\n","\n","numpy-base-1.23.1    | 5.6 MB    | :  22% 0.2224665180863521/1 [00:03<00:03,  4.79s/it] \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","\n","\n","\n","\n","libstdcxx-ng-11.2.0  | 4.7 MB    | :  64% 0.6427132677580345/1 [00:03<00:01,  4.17s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","\n","\n","numpy-base-1.23.1    | 5.6 MB    | :  26% 0.2586173272753843/1 [00:03<00:03,  4.16s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","\n","\n","numpy-base-1.23.1    | 5.6 MB    | :  29% 0.2919873049883371/1 [00:03<00:02,  3.87s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","\n","\n","numpy-base-1.23.1    | 5.6 MB    | :  33% 0.32535728270128994/1 [00:03<00:02,  3.63s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","\n","\n","\n","\n","libstdcxx-ng-11.2.0  | 4.7 MB    | :  78% 0.775918090091306/1 [00:04<00:00,  3.77s/it] \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","\n","\n","numpy-base-1.23.1    | 5.6 MB    | :  36% 0.35872726041424274/1 [00:04<00:02,  3.49s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","mkl-2021.4.0         | 142.6 MB  | :  85% 0.8501690567375819/1 [00:04<00:02, 17.83s/it]\u001b[A\u001b[A\n","\n","\n","\n","\n","\n","numpy-base-1.23.1    | 5.6 MB    | :  39% 0.39487806960327493/1 [00:04<00:02,  3.31s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","\n","\n","numpy-base-1.23.1    | 5.6 MB    | :  43% 0.43102887879230717/1 [00:04<00:01,  3.19s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","\n","\n","\n","\n","libstdcxx-ng-11.2.0  | 4.7 MB    | :  87% 0.8724915862829278/1 [00:04<00:00,  3.49s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","\n","\n","numpy-base-1.23.1    | 5.6 MB    | :  47% 0.46717968798133935/1 [00:04<00:01,  3.11s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","\n","\n","numpy-base-1.23.1    | 5.6 MB    | :  50% 0.5005496656942922/1 [00:04<00:01,  3.10s/it] \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","\n","\n","\n","\n","libstdcxx-ng-11.2.0  | 4.7 MB    | :  95% 0.9490843591245588/1 [00:04<00:00,  3.29s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","\n","\n","numpy-base-1.23.1    | 5.6 MB    | :  54% 0.5367004748833244/1 [00:04<00:01,  3.05s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","\n","\n","\n","\n","libstdcxx-ng-11.2.0  | 4.7 MB    | : 100% 1.0/1 [00:04<00:00,  3.29s/it]               \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","\n","\n","\n","\n","\n","pytorch-1.12.1       | 1.19 GB   | :  10% 0.09578636533752725/1 [00:04<03:13, 214.55s/it]\n","\n","\n","\n","\n","\n","numpy-base-1.23.1    | 5.6 MB    | :  57% 0.5700704525962772/1 [00:04<00:01,  3.10s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","\n","\n","\n","\n","\n","intel-openmp-2021.4. | 4.2 MB    | :   5% 0.04875669199286615/1 [00:04<01:07, 70.88s/it]   \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n","cudatoolkit-11.3.1   | 549.3 MB  | :   9% 0.08536801097645423/1 [00:04<01:31, 99.50s/it]\u001b[A\n","\n","\n","\n","\n","\n","numpy-base-1.23.1    | 5.6 MB    | :  61% 0.6062212617853094/1 [00:04<00:01,  3.07s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","\n","\n","\n","\n","\n","intel-openmp-2021.4. | 4.2 MB    | :   9% 0.09376286921705028/1 [00:04<00:28, 31.52s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","\n","\n","numpy-base-1.23.1    | 5.6 MB    | :  64% 0.6395912394982622/1 [00:04<00:01,  3.09s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","\n","\n","\n","\n","\n","intel-openmp-2021.4. | 4.2 MB    | :  14% 0.13876904644123442/1 [00:04<00:15, 18.39s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","\n","\n","numpy-base-1.23.1    | 5.6 MB    | :  68% 0.6757420486872945/1 [00:05<00:00,  3.06s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","\n","\n","\n","\n","\n","intel-openmp-2021.4. | 4.2 MB    | :  18% 0.18377522366541857/1 [00:05<00:09, 12.08s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","\n","\n","numpy-base-1.23.1    | 5.6 MB    | :  71% 0.7091120264002473/1 [00:05<00:00,  3.11s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","\n","\n","\n","\n","\n","intel-openmp-2021.4. | 4.2 MB    | :  23% 0.2287814008896027/1 [00:05<00:06,  8.56s/it] \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","\n","\n","numpy-base-1.23.1    | 5.6 MB    | :  75% 0.7452628355892795/1 [00:05<00:00,  3.07s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","mkl-2021.4.0         | 142.6 MB  | :  86% 0.8648498110678442/1 [00:05<00:04, 30.89s/it]\u001b[A\u001b[A\n","\n","\n","\n","\n","\n","\n","\n","\n","intel-openmp-2021.4. | 4.2 MB    | :  28% 0.27753809288246883/1 [00:05<00:04,  6.30s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","\n","\n","numpy-base-1.23.1    | 5.6 MB    | :  78% 0.7786328133022323/1 [00:05<00:00,  3.10s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","\n","\n","\n","\n","\n","intel-openmp-2021.4. | 4.2 MB    | :  32% 0.322544270106653/1 [00:05<00:03,  5.02s/it]  \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","\n","\n","numpy-base-1.23.1    | 5.6 MB    | :  81% 0.8120027910151851/1 [00:05<00:00,  3.14s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","\n","\n","\n","\n","\n","intel-openmp-2021.4. | 4.2 MB    | :  37% 0.36755044733083714/1 [00:05<00:02,  4.18s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","\n","\n","numpy-base-1.23.1    | 5.6 MB    | :  85% 0.8453727687281379/1 [00:05<00:00,  3.14s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","\n","\n","\n","\n","\n","intel-openmp-2021.4. | 4.2 MB    | :  41% 0.41255662455502123/1 [00:05<00:02,  3.61s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","\n","\n","pytorch-1.12.1       | 1.19 GB   | :  10% 0.09725646169597056/1 [00:05<04:49, 320.88s/it]\n","\n","\n","\n","\n","\n","\n","\n","\n","intel-openmp-2021.4. | 4.2 MB    | :  46% 0.4575628017792054/1 [00:05<00:02,  3.77s/it] \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","\n","\n","numpy-base-1.23.1    | 5.6 MB    | :  91% 0.9121127241540435/1 [00:05<00:00,  3.85s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n","cudatoolkit-11.3.1   | 549.3 MB  | :   9% 0.08852557486128809/1 [00:05<02:12, 145.70s/it]\u001b[A\n","\n","\n","\n","\n","\n","\n","\n","\n","intel-openmp-2021.4. | 4.2 MB    | :  50% 0.4950679494660255/1 [00:05<00:01,  3.72s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","\n","\n","numpy-base-1.23.1    | 5.6 MB    | :  94% 0.9427018703909169/1 [00:05<00:00,  4.05s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","\n","\n","\n","\n","\n","intel-openmp-2021.4. | 4.2 MB    | :  54% 0.5400741266902096/1 [00:06<00:01,  3.26s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","\n","\n","numpy-base-1.23.1    | 5.6 MB    | :  98% 0.9760718481038697/1 [00:06<00:00,  3.79s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","\n","\n","\n","\n","\n","intel-openmp-2021.4. | 4.2 MB    | :  59% 0.5850803039143938/1 [00:06<00:01,  2.97s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","\n","\n","numpy-base-1.23.1    | 5.6 MB    | : 100% 1.0/1 [00:06<00:00,  3.79s/it]               \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","openssl-1.1.1w       | 3.7 MB    | :   0% 0.004187193943698291/1 [00:06<24:45, 1491.57s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","\n","\n","\n","\n","\n","intel-openmp-2021.4. | 4.2 MB    | :  63% 0.6300864811385779/1 [00:06<00:01,  2.77s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","mkl-2021.4.0         | 142.6 MB  | :  88% 0.875476924277064/1 [00:06<00:05, 42.00s/it] \u001b[A\u001b[A\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","openssl-1.1.1w       | 3.7 MB    | :   6% 0.05862071521177607/1 [00:06<01:13, 78.09s/it]   \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","\n","\n","\n","\n","\n","pytorch-1.12.1       | 1.19 GB   | :  10% 0.09833027120996393/1 [00:06<05:39, 376.22s/it]\n","\n","\n","\n","\n","\n","\n","\n","\n","intel-openmp-2021.4. | 4.2 MB    | :  73% 0.7275998651243102/1 [00:06<00:00,  2.41s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","openssl-1.1.1w       | 3.7 MB    | :  15% 0.1465517880294402/1 [00:06<00:21, 25.30s/it] \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n","cudatoolkit-11.3.1   | 549.3 MB  | :   9% 0.09082974310157226/1 [00:06<02:31, 166.41s/it]\u001b[A\n","\n","pytorch-1.12.1       | 1.19 GB   | :  10% 0.10097644465516187/1 [00:06<03:42, 247.09s/it]\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","openssl-1.1.1w       | 3.7 MB    | :  86% 0.862561952401848/1 [00:06<00:00,  2.94s/it] \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n","cudatoolkit-11.3.1   | 549.3 MB  | :  10% 0.09708797782827/1 [00:06<01:36, 106.39s/it]   \u001b[A\n","\n","\n","\n","\n","\n","\n","\n","\n","intel-openmp-2021.4. | 4.2 MB    | : 100% 1.0/1 [00:06<00:00,  1.00s/it]               \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","\n","\n","\n","\n","\n","intel-openmp-2021.4. | 4.2 MB    | : 100% 1.0/1 [00:06<00:00,  1.00s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","mkl-2021.4.0         | 142.6 MB  | :  91% 0.9067009166959056/1 [00:06<00:02, 25.13s/it]\u001b[A\u001b[A\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","pytorch-1.12.1       | 1.19 GB   | :  10% 0.1039038539254533/1 [00:06<02:29, 167.17s/it] \n","cudatoolkit-11.3.1   | 549.3 MB  | :  11% 0.1062477577464367/1 [00:06<00:56, 63.00s/it]\u001b[A\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","openssl-1.1.1w       | 3.7 MB    | : 100% 1.0/1 [00:06<00:00,  2.94s/it]              \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","mkl-2021.4.0         | 142.6 MB  | :  93% 0.9323374578397966/1 [00:06<00:01, 16.88s/it]\u001b[A\u001b[A\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","tk-8.6.14            | 3.4 MB    | : 100% 1.0/1 [00:06<00:00,  4.78s/it]                   \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","pytorch-1.12.1       | 1.19 GB   | :  11% 0.10709971557424308/1 [00:06<01:44, 117.32s/it]\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","setuptools-75.1.0    | 1.7 MB    | :   1% 0.00924925453853649/1 [00:06<12:04, 731.50s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n","cudatoolkit-11.3.1   | 549.3 MB  | :  11% 0.11495239332084357/1 [00:06<00:38, 43.74s/it]\u001b[A\n","\n","pytorch-1.12.1       | 1.19 GB   | :  11% 0.11052567926174572/1 [00:06<01:16, 85.58s/it] \n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","setuptools-75.1.0    | 1.7 MB    | : 100% 1.0/1 [00:06<00:00, 731.50s/it]                \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n","cudatoolkit-11.3.1   | 549.3 MB  | :  12% 0.12428285236792021/1 [00:06<00:27, 31.55s/it]\u001b[A\n","\n","mkl-2021.4.0         | 142.6 MB  | :  98% 0.9814193827648529/1 [00:06<00:00,  9.62s/it]\u001b[A\u001b[A\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","sqlite-3.45.3        | 1.2 MB    | :   1% 0.012744531418334731/1 [00:06<08:53, 540.61s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","sqlite-3.45.3        | 1.2 MB    | : 100% 1.0/1 [00:06<00:00, 540.61s/it]                 \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","pytorch-1.12.1       | 1.19 GB   | :  11% 0.11308236858077754/1 [00:07<01:05, 74.01s/it]\n","cudatoolkit-11.3.1   | 549.3 MB  | :  13% 0.1320771992548074/1 [00:07<00:22, 25.88s/it] \u001b[A\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","gnutls-3.6.15        | 1.0 MB    | : 100% 1.0/1 [00:06<00:00, 447.93s/it]                 \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","ncurses-6.4          | 914 KB    | :   2% 0.01750655534161504/1 [00:07<06:33, 400.19s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","pytorch-1.12.1       | 1.19 GB   | :  12% 0.11648276537508986/1 [00:07<00:51, 58.79s/it]\n","cudatoolkit-11.3.1   | 549.3 MB  | :  14% 0.13975776005575463/1 [00:07<00:18, 22.01s/it]\u001b[A\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","nettle-3.7.3         | 809 KB    | :   2% 0.019767242648212092/1 [00:07<05:50, 358.07s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","nettle-3.7.3         | 809 KB    | : 100% 1.0/1 [00:07<00:00, 358.07s/it]                 \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","pillow-10.4.0        | 795 KB    | :   2% 0.02013308183365385/1 [00:07<05:46, 354.13s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","pillow-10.4.0        | 795 KB    | : 100% 1.0/1 [00:07<00:00, 354.13s/it]                \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","pytorch-1.12.1       | 1.19 GB   | :  12% 0.11989594561599735/1 [00:07<00:44, 51.07s/it]\n","cudatoolkit-11.3.1   | 549.3 MB  | :  15% 0.147040069555912/1 [00:07<00:17, 20.65s/it]  \u001b[A\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","pip-20.3.3           | 1.8 MB    | :   1% 0.008820557325277971/1 [00:07<13:34, 821.42s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n"," ... (more hidden) ...\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","pytorch-1.12.1       | 1.19 GB   | :  12% 0.12293840590564523/1 [00:07<00:40, 45.79s/it]\n","cudatoolkit-11.3.1   | 549.3 MB  | :  15% 0.15386723471230954/1 [00:07<00:17, 20.14s/it]\u001b[A\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","pytorch-1.12.1       | 1.19 GB   | :  13% 0.12627488546698176/1 [00:07<00:35, 41.13s/it]\n","cudatoolkit-11.3.1   | 549.3 MB  | :  16% 0.16066595334722208/1 [00:07<00:15, 18.60s/it]\u001b[A\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","pytorch-1.12.1       | 1.19 GB   | :  13% 0.13008435255233916/1 [00:07<00:31, 36.06s/it]\n","cudatoolkit-11.3.1   | 549.3 MB  | :  17% 0.16828962110519935/1 [00:07<00:14, 16.88s/it]\u001b[A\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","pytorch-1.12.1       | 1.19 GB   | :  13% 0.13329299764772412/1 [00:07<00:31, 36.32s/it]\n","cudatoolkit-11.3.1   | 549.3 MB  | :  18% 0.17514523278308186/1 [00:07<00:13, 16.38s/it]\u001b[A\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","pytorch-1.12.1       | 1.19 GB   | :  14% 0.13634824138396714/1 [00:07<00:31, 36.53s/it]\n","pytorch-1.12.1       | 1.19 GB   | :  14% 0.1393651347804247/1 [00:07<00:30, 35.71s/it] \n","cudatoolkit-11.3.1   | 549.3 MB  | :  19% 0.19064858699240128/1 [00:07<00:11, 14.63s/it]\u001b[A\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","pytorch-1.12.1       | 1.19 GB   | :  14% 0.1437115066227788/1 [00:07<00:27, 31.53s/it]\n","cudatoolkit-11.3.1   | 549.3 MB  | :  20% 0.19915409691641323/1 [00:07<00:11, 13.77s/it]\u001b[A\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","pytorch-1.12.1       | 1.19 GB   | :  15% 0.14700963584432983/1 [00:08<00:26, 31.37s/it]\n","cudatoolkit-11.3.1   | 549.3 MB  | :  21% 0.2067208716314205/1 [00:08<00:11, 13.96s/it] \u001b[A\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","pytorch-1.12.1       | 1.19 GB   | :  15% 0.15049951676480827/1 [00:08<00:26, 30.91s/it]\n","cudatoolkit-11.3.1   | 549.3 MB  | :  21% 0.2141454137390028/1 [00:08<00:10, 13.98s/it]\u001b[A\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","pip-20.3.3           | 1.8 MB    | :  81% 0.8114912739255733/1 [00:08<00:00,  1.55s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","pytorch-1.12.1       | 1.19 GB   | :  15% 0.154334550743356/1 [00:08<00:24, 29.43s/it]  \n","cudatoolkit-11.3.1   | 549.3 MB  | :  22% 0.22262247714152975/1 [00:08<00:10, 13.37s/it]\u001b[A\n","pytorch-1.12.1       | 1.19 GB   | :  16% 0.15778608132404898/1 [00:08<00:27, 32.30s/it]\n","pytorch-1.12.1       | 1.19 GB   | :  16% 0.16195348491407086/1 [00:08<00:24, 29.80s/it]\n","pytorch-1.12.1       | 1.19 GB   | :  17% 0.16715634767830062/1 [00:08<00:22, 27.58s/it]\n","pytorch-1.12.1       | 1.19 GB   | :  17% 0.17146436918086924/1 [00:08<00:22, 26.84s/it]\n","pytorch-1.12.1       | 1.19 GB   | :  18% 0.175222702479846/1 [00:08<00:22, 27.56s/it]  \n","pytorch-1.12.1       | 1.19 GB   | :  18% 0.17887876820606152/1 [00:08<00:22, 27.97s/it]\n","pytorch-1.12.1       | 1.19 GB   | :  19% 0.1868300719882505/1 [00:09<00:21, 26.72s/it] \n","pytorch-1.12.1       | 1.19 GB   | :  19% 0.19099747557827237/1 [00:09<00:21, 26.08s/it]\n","pytorch-1.12.1       | 1.19 GB   | :  20% 0.19551003222636354/1 [00:09<00:20, 25.17s/it]\n","pytorch-1.12.1       | 1.19 GB   | :  20% 0.1997413530493612/1 [00:09<00:19, 24.77s/it] \n","pytorch-1.12.1       | 1.19 GB   | :  20% 0.20424112625085722/1 [00:09<00:19, 24.60s/it]\n","pytorch-1.12.1       | 1.19 GB   | :  21% 0.2088431670251145/1 [00:09<00:18, 23.69s/it] \n","cudatoolkit-11.3.1   | 549.3 MB  | :  34% 0.34076088086869216/1 [00:09<00:07, 11.34s/it]\u001b[A\n","pytorch-1.12.1       | 1.19 GB   | :  21% 0.21307448784811214/1 [00:09<00:21, 26.94s/it]\n","\n","mkl-2021.4.0         | 142.6 MB  | : 100% 1.0/1 [00:09<00:00,  9.62s/it]               \u001b[A\u001b[A\n","pytorch-1.12.1       | 1.19 GB   | :  22% 0.2169095218266599/1 [00:10<00:26, 33.22s/it] \n","pytorch-1.12.1       | 1.19 GB   | :  22% 0.22208681769769933/1 [00:10<00:22, 28.47s/it]\n","pytorch-1.12.1       | 1.19 GB   | :  23% 0.2261903040547454/1 [00:10<00:21, 27.32s/it] \n","pytorch-1.12.1       | 1.19 GB   | :  23% 0.23011482215945925/1 [00:10<00:20, 26.87s/it]\n","\n","\n","\n","\n","ffmpeg-4.3           | 9.9 MB    | : 100% 1.0/1 [00:10<00:00,  1.37s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n","pytorch-1.12.1       | 1.19 GB   | :  23% 0.2347935636132875/1 [00:10<00:19, 25.18s/it] \n","pytorch-1.12.1       | 1.19 GB   | :  24% 0.23990694225135115/1 [00:10<00:17, 23.40s/it]\n","pytorch-1.12.1       | 1.19 GB   | :  24% 0.24431723132668104/1 [00:10<00:18, 24.02s/it]\n","pytorch-1.12.1       | 1.19 GB   | :  25% 0.249456176857935/1 [00:10<00:17, 23.49s/it]  \n","pytorch-1.12.1       | 1.19 GB   | :  25% 0.2537769818070988/1 [00:10<00:17, 23.41s/it]\n","pytorch-1.12.1       | 1.19 GB   | :  26% 0.25809778675626255/1 [00:10<00:17, 23.41s/it]\n","pytorch-1.12.1       | 1.19 GB   | :  26% 0.2624058082588312/1 [00:11<00:17, 24.04s/it] \n","pytorch-1.12.1       | 1.19 GB   | :  27% 0.26826062679941404/1 [00:11<00:15, 21.53s/it]\n","pytorch-1.12.1       | 1.19 GB   | :  27% 0.27411544533999693/1 [00:11<00:14, 20.31s/it]\n","pytorch-1.12.1       | 1.19 GB   | :  28% 0.28090345548202644/1 [00:11<00:13, 18.32s/it]\n","pytorch-1.12.1       | 1.19 GB   | :  29% 0.28640033751794486/1 [00:11<00:13, 18.52s/it]\n","pytorch-1.12.1       | 1.19 GB   | :  29% 0.2918333023208875/1 [00:11<00:14, 20.72s/it] \n","pytorch-1.12.1       | 1.19 GB   | :  30% 0.2967932795998092/1 [00:11<00:15, 21.69s/it]\n","pytorch-1.12.1       | 1.19 GB   | :  30% 0.30149758794682774/1 [00:11<00:15, 22.66s/it]\n","pytorch-1.12.1       | 1.19 GB   | :  31% 0.3059845777017286/1 [00:11<00:16, 23.84s/it] \n","pytorch-1.12.1       | 1.19 GB   | :  31% 0.3102414654179166/1 [00:12<00:16, 24.02s/it]\n","pytorch-1.12.1       | 1.19 GB   | :  32% 0.31954781453919245/1 [00:12<00:15, 22.89s/it]\n","pytorch-1.12.1       | 1.19 GB   | :  32% 0.3239581036145223/1 [00:12<00:15, 22.95s/it] \n","pytorch-1.12.1       | 1.19 GB   | :  33% 0.329557253223202/1 [00:12<00:14, 21.21s/it] \n","pytorch-1.12.1       | 1.19 GB   | :  33% 0.33499021802614465/1 [00:12<00:13, 20.38s/it]\n","pytorch-1.12.1       | 1.19 GB   | :  34% 0.3399246284118761/1 [00:12<00:14, 21.32s/it] \n","pytorch-1.12.1       | 1.19 GB   | :  35% 0.34554934491374606/1 [00:12<00:13, 20.17s/it]\n","cudatoolkit-11.3.1   | 549.3 MB  | :  66% 0.6565457158735634/1 [00:12<00:03,  8.94s/it]\u001b[A\n","pytorch-1.12.1       | 1.19 GB   | :  36% 0.3551752801999009/1 [00:13<00:14, 22.65s/it]\n","pytorch-1.12.1       | 1.19 GB   | :  36% 0.35966226995480177/1 [00:13<00:14, 23.26s/it]\n","pytorch-1.12.1       | 1.19 GB   | :  36% 0.3643665783018203/1 [00:13<00:14, 22.69s/it] \n","pytorch-1.12.1       | 1.19 GB   | :  37% 0.36881521771693565/1 [00:13<00:15, 24.07s/it]\n","pytorch-1.12.1       | 1.19 GB   | :  37% 0.373340557811622/1 [00:13<00:14, 23.79s/it]  \n","pytorch-1.12.1       | 1.19 GB   | :  38% 0.37759744552781/1 [00:13<00:14, 23.92s/it] \n","pytorch-1.12.1       | 1.19 GB   | :  38% 0.3819821677099496/1 [00:13<00:14, 23.60s/it]\n","pytorch-1.12.1       | 1.19 GB   | :  39% 0.38623905542613757/1 [00:15<01:36, 157.56s/it]\n","pytorch-1.12.1       | 1.19 GB   | :  39% 0.3892815157157854/1 [00:16<01:58, 194.74s/it] \n","pytorch-1.12.1       | 1.19 GB   | :  39% 0.3935128365387831/1 [00:16<01:25, 141.59s/it]\n","pytorch-1.12.1       | 1.19 GB   | :  40% 0.39802539318687424/1 [00:16<01:02, 103.37s/it]\n","pytorch-1.12.1       | 1.19 GB   | :  40% 0.40141300653459144/1 [00:17<00:50, 84.44s/it] \n","pytorch-1.12.1       | 1.19 GB   | :  41% 0.40570824459056487/1 [00:17<00:38, 65.49s/it]\n","pytorch-1.12.1       | 1.19 GB   | :  41% 0.41015688400568023/1 [00:17<00:30, 51.81s/it]\n","cudatoolkit-11.3.1   | 549.3 MB  | :  82% 0.8199425352833445/1 [00:17<00:03, 21.70s/it]\u001b[A\n","\n","\n","pytorch-1.12.1       | 1.19 GB   | :  41% 0.4139535676444425/1 [00:17<00:26, 44.87s/it] \n","pytorch-1.12.1       | 1.19 GB   | :  42% 0.4183894236129627/1 [00:17<00:21, 37.75s/it]\n","pytorch-1.12.1       | 1.19 GB   | :  42% 0.4223650755040572/1 [00:17<00:22, 39.36s/it]\n","cudatoolkit-11.3.1   | 549.3 MB  | :  85% 0.8476778937312095/1 [00:17<00:02, 15.86s/it]\u001b[A\n","pytorch-1.12.1       | 1.19 GB   | :  43% 0.42584217297794047/1 [00:17<00:23, 41.55s/it]\n","pytorch-1.12.1       | 1.19 GB   | :  43% 0.4300734938009382/1 [00:17<00:20, 35.89s/it] \n","pytorch-1.12.1       | 1.19 GB   | :  43% 0.4340619291386278/1 [00:17<00:18, 32.81s/it]\n","pytorch-1.12.1       | 1.19 GB   | :  44% 0.43926479190285755/1 [00:18<00:15, 27.95s/it]\n","\n","\n","\n","\n","\n","\n","libgcc-ng-11.2.0     | 5.3 MB    | : 100% 1.0/1 [00:18<00:00,  2.49s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n","pytorch-1.12.1       | 1.19 GB   | :  44% 0.443317144473523/1 [00:18<00:15, 28.44s/it]  \n","pytorch-1.12.1       | 1.19 GB   | :  45% 0.451268448255712/1 [00:18<00:16, 29.33s/it] \n","pytorch-1.12.1       | 1.19 GB   | :  46% 0.4551673994672355/1 [00:18<00:15, 28.56s/it]\n","pytorch-1.12.1       | 1.19 GB   | :  46% 0.4589129493196171/1 [00:18<00:15, 28.04s/it]\n","pytorch-1.12.1       | 1.19 GB   | :  46% 0.4626073653856181/1 [00:18<00:15, 29.16s/it]\n","cudatoolkit-11.3.1   | 549.3 MB  | :  94% 0.9419496659324655/1 [00:18<00:00, 13.50s/it]\u001b[A\n","\n","\n","\n","\n","\n","\n","\n","pytorch-1.12.1       | 1.19 GB   | :  47% 0.46678755242223513/1 [00:18<00:14, 27.64s/it]\n","pytorch-1.12.1       | 1.19 GB   | :  47% 0.4704947519348313/1 [00:18<00:14, 28.20s/it] \n","pytorch-1.12.1       | 1.19 GB   | :  47% 0.47409968387466617/1 [00:19<00:14, 28.32s/it]\n","pytorch-1.12.1       | 1.19 GB   | :  48% 0.47813925299873644/1 [00:19<00:14, 27.21s/it]\n","pytorch-1.12.1       | 1.19 GB   | :  48% 0.4821532552296164/1 [00:19<00:14, 27.35s/it] \n","pytorch-1.12.1       | 1.19 GB   | :  49% 0.48655076085835114/1 [00:19<00:13, 26.59s/it]\n","pytorch-1.12.1       | 1.19 GB   | :  57% 0.5718802668810382/1 [00:21<00:08, 19.13s/it]\n","\n","\n","\n","\n","\n","pytorch-1.12.1       | 1.19 GB   | :  60% 0.5979584979351629/1 [00:22<00:14, 35.29s/it]\n","\n","\n","\n","\n","\n","\n","\n","\n","pytorch-1.12.1       | 1.19 GB   | :  61% 0.6128895635583087/1 [00:23<00:10, 25.93s/it]\n","\n","\n","\n","pytorch-1.12.1       | 1.19 GB   | :  62% 0.6177089229246837/1 [00:23<00:09, 24.77s/it]\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","pytorch-1.12.1       | 1.19 GB   | :  66% 0.6604312014457054/1 [00:24<00:06, 18.76s/it]\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","pytorch-1.12.1       | 1.19 GB   | :  67% 0.6658385993554577/1 [00:24<00:06, 19.18s/it]\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","sqlite-3.45.3        | 1.2 MB    | : 100% 1.0/1 [00:24<00:00, 22.33s/it] \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","sqlite-3.45.3        | 1.2 MB    | : 100% 1.0/1 [00:24<00:00, 22.33s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n","pytorch-1.12.1       | 1.19 GB   | :  67% 0.6719363033813487/1 [00:24<00:06, 18.29s/it]\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","gnutls-3.6.15        | 1.0 MB    | : 100% 1.0/1 [00:24<00:00, 22.45s/it] \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","pytorch-1.12.1       | 1.19 GB   | :  70% 0.6990499936096811/1 [00:24<00:06, 20.71s/it]\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","setuptools-75.1.0    | 1.7 MB    | : 100% 1.0/1 [00:24<00:00, 23.00s/it] \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","pytorch-1.12.1       | 1.19 GB   | :  70% 0.7039460536556271/1 [00:25<00:06, 20.65s/it]\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","nettle-3.7.3         | 809 KB    | : 100% 1.0/1 [00:25<00:00, 23.13s/it] \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","pytorch-1.12.1       | 1.19 GB   | :  72% 0.7205389673361436/1 [00:25<00:05, 20.29s/it]\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","pillow-10.4.0        | 795 KB    | : 100% 1.0/1 [00:25<00:00, 23.41s/it] \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","pytorch-1.12.1       | 1.19 GB   | :  73% 0.7255117280616605/1 [00:25<00:05, 20.53s/it]\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","pytorch-1.12.1       | 1.19 GB   | :  79% 0.7946701741414713/1 [00:26<00:03, 17.64s/it]\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","ncurses-6.4          | 914 KB    | : 100% 1.0/1 [00:26<00:00, 24.77s/it] \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","pytorch-1.12.1       | 1.19 GB   | :  85% 0.8545222711000063/1 [00:28<00:03, 23.51s/it]\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","pip-20.3.3           | 1.8 MB    | : 100% 1.0/1 [00:28<00:00, 38.57s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","pytorch-1.12.1       | 1.19 GB   | : 100% 1.0/1 [00:38<00:00, 53.89s/it]               \n","\n","mkl-2021.4.0         | 142.6 MB  | : 100% 1.0/1 [00:49<00:00,  9.62s/it]\u001b[A\u001b[A\n","pytorch-1.12.1       | 1.19 GB   | : 100% 1.0/1 [03:32<00:00, 53.89s/it]\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","                                                                        \n","                                                                        \u001b[A\n","\n","                                                                        \u001b[A\u001b[A\n","\n","\n","                                                                        \u001b[A\u001b[A\u001b[A\n","\n","\n","\n","                                                                        \u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","\n","                                                                        \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","\n","\n","                                                                        \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","\n","\n","\n","                                                                        \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","\n","\n","\n","\n","                                                                        \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","\n","\n","\n","\n","\n","                                                                        \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","                                                                        \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","                                                                        \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","                                                                        \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","                                                                        \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","                                                                        \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","                                                                        \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","                                                                        \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","                                                                        \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","                                                                        \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n","\u001b[A\n","\n","\u001b[A\u001b[A\n","\n","\n","\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","\n","\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","\n","\n","\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","\n","\n","\n","\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","\n","\n","\n","\n","\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","\n","\n","\n","\n","\n","\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n","\u001b[A\n","\n","\u001b[A\u001b[A\n","\n","\n","\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","\n","\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","\n","\n","\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","\n","\n","\n","\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","\n","\n","\n","\n","\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","\n","\n","\n","\n","\n","\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n","\u001b[A\n","\n","\u001b[A\u001b[A\n","\n","\n","\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","\n","\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n","Preparing transaction: - \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\bdone\n","Verifying transaction: - \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\bdone\n","Executing transaction: / \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| By downloading and using the CUDA Toolkit conda packages, you accept the terms and conditions of the CUDA End User License Agreement (EULA): https://docs.nvidia.com/cuda/eula/index.html\n","\n","\b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\bdone\n","Installing pip dependencies: \\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ Ran pip subprocess with arguments:\n","['/usr/local/envs/defake/bin/python', '-m', 'pip', 'install', '-U', '-r', '/content/De-Fake/condaenv.mt3qq2py.requirements.txt', '--exists-action=b']\n","Pip subprocess output:\n","Requirement already satisfied: Pillow in /usr/local/envs/defake/lib/python3.8/site-packages (from -r /content/De-Fake/condaenv.mt3qq2py.requirements.txt (line 2)) (10.4.0)\n","Collecting git+https://github.com/openai/CLIP.git (from -r /content/De-Fake/condaenv.mt3qq2py.requirements.txt (line 6))\n","  Cloning https://github.com/openai/CLIP.git to /tmp/pip-req-build-txihavfp\n","Requirement already satisfied: torch in /usr/local/envs/defake/lib/python3.8/site-packages (from clip==1.0->-r /content/De-Fake/condaenv.mt3qq2py.requirements.txt (line 6)) (1.12.1)\n","Requirement already satisfied: torchvision in /usr/local/envs/defake/lib/python3.8/site-packages (from clip==1.0->-r /content/De-Fake/condaenv.mt3qq2py.requirements.txt (line 6)) (0.13.1)\n","Collecting fairscale==0.4.4\n","  Downloading fairscale-0.4.4.tar.gz (235 kB)\n","  Installing build dependencies: started\n","  Installing build dependencies: finished with status 'done'\n","  Getting requirements to build wheel: started\n","  Getting requirements to build wheel: finished with status 'done'\n","  Installing backend dependencies: started\n","  Installing backend dependencies: finished with status 'done'\n","    Preparing wheel metadata: started\n","    Preparing wheel metadata: finished with status 'done'\n","Collecting transformers==4.15.0\n","  Downloading transformers-4.15.0-py3-none-any.whl (3.4 MB)\n","Requirement already satisfied: numpy>=1.17 in /usr/local/envs/defake/lib/python3.8/site-packages (from transformers==4.15.0->-r /content/De-Fake/condaenv.mt3qq2py.requirements.txt (line 11)) (1.23.1)\n","Requirement already satisfied: requests in /usr/local/envs/defake/lib/python3.8/site-packages (from transformers==4.15.0->-r /content/De-Fake/condaenv.mt3qq2py.requirements.txt (line 11)) (2.32.3)\n","Collecting regex\n","  Downloading regex-2024.11.6-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (785 kB)\n","Collecting tqdm\n","  Downloading tqdm-4.67.1-py3-none-any.whl (78 kB)\n","Collecting huggingface-hub<1.0,>=0.1.0\n","  Downloading huggingface_hub-0.28.1-py3-none-any.whl (464 kB)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/envs/defake/lib/python3.8/site-packages (from huggingface-hub<1.0,>=0.1.0->transformers==4.15.0->-r /content/De-Fake/condaenv.mt3qq2py.requirements.txt (line 11)) (4.11.0)\n","Collecting fsspec>=2023.5.0\n","  Downloading fsspec-2025.2.0-py3-none-any.whl (184 kB)\n","Collecting packaging\n","  Downloading packaging-24.2-py3-none-any.whl (65 kB)\n","Collecting pyyaml>=5.1\n","  Downloading PyYAML-6.0.2-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (746 kB)\n","Collecting tokenizers<0.11,>=0.10.1\n","  Downloading tokenizers-0.10.3-cp38-cp38-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (3.3 MB)\n","Collecting ftfy\n","  Downloading ftfy-6.2.3-py3-none-any.whl (43 kB)\n","Collecting wcwidth<0.3.0,>=0.2.12\n","  Downloading wcwidth-0.2.13-py2.py3-none-any.whl (34 kB)\n","Collecting natsort\n","  Downloading natsort-8.4.0-py3-none-any.whl (38 kB)\n","Collecting pycocoevalcap\n","  Downloading pycocoevalcap-1.2-py3-none-any.whl (104.3 MB)\n","Collecting pycocotools>=2.0.2\n","  Downloading pycocotools-2.0.7-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (439 kB)\n","Collecting matplotlib>=2.1.0\n","  Downloading matplotlib-3.7.5-cp38-cp38-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (9.2 MB)\n","Collecting contourpy>=1.0.1\n","  Downloading contourpy-1.1.1-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (301 kB)\n","Collecting cycler>=0.10\n","  Downloading cycler-0.12.1-py3-none-any.whl (8.3 kB)\n","Collecting fonttools>=4.22.0\n","  Downloading fonttools-4.55.8-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.7 MB)\n","Collecting importlib-resources>=3.2.0\n","  Downloading importlib_resources-6.4.5-py3-none-any.whl (36 kB)\n","Collecting kiwisolver>=1.0.1\n","  Downloading kiwisolver-1.4.7-cp38-cp38-manylinux_2_5_x86_64.manylinux1_x86_64.whl (1.2 MB)\n","Collecting pyparsing>=2.3.1\n","  Downloading pyparsing-3.1.4-py3-none-any.whl (104 kB)\n","Collecting python-dateutil>=2.7\n","  Downloading python_dateutil-2.9.0.post0-py2.py3-none-any.whl (229 kB)\n","Requirement already satisfied: six>=1.5 in /usr/local/envs/defake/lib/python3.8/site-packages (from python-dateutil>=2.7->matplotlib>=2.1.0->pycocotools>=2.0.2->pycocoevalcap->-r /content/De-Fake/condaenv.mt3qq2py.requirements.txt (line 8)) (1.16.0)\n","Collecting zipp>=3.1.0\n","  Downloading zipp-3.20.2-py3-none-any.whl (9.2 kB)\n","Collecting scikit-learn\n","  Downloading scikit_learn-1.3.2-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (11.1 MB)\n","Collecting joblib>=1.1.1\n","  Downloading joblib-1.4.2-py3-none-any.whl (301 kB)\n","Collecting scipy>=1.5.0\n","  Downloading scipy-1.10.1-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (34.5 MB)\n","Collecting threadpoolctl>=2.0.0\n","  Downloading threadpoolctl-3.5.0-py3-none-any.whl (18 kB)\n","Collecting timm\n","  Downloading timm-1.0.14-py3-none-any.whl (2.4 MB)\n","Collecting filelock\n","  Downloading filelock-3.16.1-py3-none-any.whl (16 kB)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/envs/defake/lib/python3.8/site-packages (from requests->transformers==4.15.0->-r /content/De-Fake/condaenv.mt3qq2py.requirements.txt (line 11)) (3.7)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/envs/defake/lib/python3.8/site-packages (from requests->transformers==4.15.0->-r /content/De-Fake/condaenv.mt3qq2py.requirements.txt (line 11)) (2024.8.30)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/envs/defake/lib/python3.8/site-packages (from requests->transformers==4.15.0->-r /content/De-Fake/condaenv.mt3qq2py.requirements.txt (line 11)) (2.2.3)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/envs/defake/lib/python3.8/site-packages (from requests->transformers==4.15.0->-r /content/De-Fake/condaenv.mt3qq2py.requirements.txt (line 11)) (3.3.2)\n","Collecting sacremoses\n","  Downloading sacremoses-0.1.1-py3-none-any.whl (897 kB)\n","Collecting click\n","  Downloading click-8.1.8-py3-none-any.whl (98 kB)\n","Collecting safetensors\n","  Downloading safetensors-0.5.2-cp38-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (461 kB)\n","Building wheels for collected packages: clip, fairscale\n","  Building wheel for clip (setup.py): started\n","  Building wheel for clip (setup.py): finished with status 'done'\n","  Created wheel for clip: filename=clip-1.0-py3-none-any.whl size=1369489 sha256=9c1789ee51de4be011368ea9a222a9b7d78e0f67463844d7c9a51818d56948df\n","  Stored in directory: /tmp/pip-ephem-wheel-cache-0egejrhr/wheels/ab/4f/3a/5e51521b55997aa6f0690e095c08824219753128ce8d9969a3\n","  Building wheel for fairscale (PEP 517): started\n","  Building wheel for fairscale (PEP 517): finished with status 'done'\n","  Created wheel for fairscale: filename=fairscale-0.4.4-py3-none-any.whl size=292831 sha256=387981a3060e477f3f51e95352551a2ee761b64512ff9d93b10835391bfa4b89\n","  Stored in directory: /root/.cache/pip/wheels/b3/c3/6e/3fca67aaef3657c2266e9ee439b54f534f05967cd8774cc65b\n","Successfully built clip fairscale\n","Installing collected packages: zipp, python-dateutil, pyparsing, packaging, kiwisolver, importlib-resources, fonttools, cycler, contourpy, wcwidth, tqdm, regex, pyyaml, matplotlib, joblib, fsspec, filelock, click, tokenizers, threadpoolctl, scipy, safetensors, sacremoses, pycocotools, huggingface-hub, ftfy, transformers, timm, scikit-learn, pycocoevalcap, natsort, fairscale, clip\n","Successfully installed click-8.1.8 clip-1.0 contourpy-1.1.1 cycler-0.12.1 fairscale-0.4.4 filelock-3.16.1 fonttools-4.55.8 fsspec-2025.2.0 ftfy-6.2.3 huggingface-hub-0.28.1 importlib-resources-6.4.5 joblib-1.4.2 kiwisolver-1.4.7 matplotlib-3.7.5 natsort-8.4.0 packaging-24.2 pycocoevalcap-1.2 pycocotools-2.0.7 pyparsing-3.1.4 python-dateutil-2.9.0.post0 pyyaml-6.0.2 regex-2024.11.6 sacremoses-0.1.1 safetensors-0.5.2 scikit-learn-1.3.2 scipy-1.10.1 threadpoolctl-3.5.0 timm-1.0.14 tokenizers-0.10.3 tqdm-4.67.1 transformers-4.15.0 wcwidth-0.2.13 zipp-3.20.2\n","\n","\b\bdone\n","#\n","# To activate this environment, use\n","#\n","#     $ conda activate defake\n","#\n","# To deactivate an active environment, use\n","#\n","#     $ conda deactivate\n","\n"]}]},{"cell_type":"code","source":["#only needed when installing librarys/deps\n","import os\n","os.kill(os.getpid(), 9)  # Force restart the runtime"],"metadata":{"id":"qw_IOweXMUwl"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["!pip uninstall torch torchvision -y\n","!pip install torch torchvision --no-cache-dir"],"metadata":{"id":"LWzlFmf251-4"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["!pip install transformers timm fairscale\n","!git clone https://github.com/salesforce/BLIP.git\n","!cd BLIP\n","!pip install -e ."],"metadata":{"id":"I42Ti7cO6wii"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["%cd De-Fake"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"d9HIx28m7KpA","executionInfo":{"status":"ok","timestamp":1738706537101,"user_tz":300,"elapsed":686,"user":{"displayName":"Rohan Wagh","userId":"06660321697866433484"}},"outputId":"8d8809b5-0fb7-48da-c1ef-a0f62c50bfbf"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["/content/De-Fake\n"]}]},{"cell_type":"markdown","source":["# IMPORTs"],"metadata":{"id":"5vIob5ZIJyZw"}},{"cell_type":"markdown","source":[],"metadata":{"id":"JhjR308JCicJ"}},{"cell_type":"code","source":["import torch\n","import torchvision\n","import torchvision.transforms as transforms\n","from torchvision import datasets, models\n","import torch.nn as nn\n","import torch.optim as optim\n","from torch.utils.data import DataLoader, Dataset, random_split\n","import torchvision\n","from natsort import natsorted\n","import torch.nn.functional as F\n","\n","import clip\n","import os\n","import sys\n","import time\n","import json\n","import random\n","import argparse\n","import numpy as np\n","from tqdm import tqdm\n","from pathlib import Path\n","from PIL import Image\n","from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, average_precision_score, confusion_matrix\n","from time import process_time_ns\n","from time import process_time_ns\n","import torch\n","import clip\n","from PIL import Image\n","import os\n","import json\n","import numpy as np\n","from pathlib import Path\n","import matplotlib.pyplot as plt\n","\n","from sklearn.metrics import confusion_matrix\n","import itertools\n","import torch.nn.functional as F\n","\n","import torch.nn as nn\n","from torch.utils.data import random_split\n","from torch import nn\n","from torchvision import transforms\n","import sys\n","import argparse\n","import time\n","from tqdm import tqdm\n","from sklearn import metrics\n","from sklearn.metrics import accuracy_score, recall_score, precision_score, roc_curve\n","from blipmodels import blip_decoder"],"metadata":{"id":"1O9LmSOSJ2Td","executionInfo":{"status":"ok","timestamp":1738706547948,"user_tz":300,"elapsed":8258,"user":{"displayName":"Rohan Wagh","userId":"06660321697866433484"}}},"execution_count":3,"outputs":[]},{"cell_type":"code","source":["class NeuralNet(nn.Module):\n","    def __init__(self, input_size, hidden_size_list, num_classes):\n","        super(NeuralNet, self).__init__()\n","        self.dropout2 = nn.Dropout(0.5)\n","        self.fc1 = nn.Linear(input_size, hidden_size_list[0])\n","        self.fc2 = nn.Linear(hidden_size_list[0], hidden_size_list[1])\n","        self.fc3 = nn.Linear(hidden_size_list[1], num_classes)\n","\n","    def forward(self, x):\n","        out = self.fc1(x)\n","        out = F.relu(out)\n","        out = self.dropout2(out)\n","        out = self.fc2(out)\n","        out = F.relu(out)\n","        out = self.fc3(out)\n","        return out\n","\n","def preprocess_image(img_path, image_size=224):\n","    img = Image.open(img_path)\n","    img = img.resize((image_size, image_size))\n","    return preprocess(img)"],"metadata":{"id":"_U0xBXo2J53E","executionInfo":{"status":"ok","timestamp":1738706559985,"user_tz":300,"elapsed":308,"user":{"displayName":"Rohan Wagh","userId":"06660321697866433484"}}},"execution_count":4,"outputs":[]},{"cell_type":"code","source":["print(np.__version__)\n","!pip list | grep numpy\n","!pip list | grep torch\n","!pip list | grep transformers"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"WCXp_FB_KHf_","executionInfo":{"status":"ok","timestamp":1738703909787,"user_tz":300,"elapsed":1238,"user":{"displayName":"Rohan Wagh","userId":"06660321697866433484"}},"outputId":"bea3c045-39bf-404b-e807-7f5cf2a53d9b"},"execution_count":5,"outputs":[{"output_type":"stream","name":"stdout","text":["1.23.5\n"]}]},{"cell_type":"code","source":["device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n","model2, preprocess = clip.load(\"ViT-B/32\")\n","\n","image_size = 224\n"],"metadata":{"id":"7y5dVPzlOaN9","executionInfo":{"status":"ok","timestamp":1738706569701,"user_tz":300,"elapsed":6080,"user":{"displayName":"Rohan Wagh","userId":"06660321697866433484"}}},"execution_count":5,"outputs":[]},{"cell_type":"code","source":["%cd ../../home\n","%mkdir -p sha/stable-diffusion/blipmodels/blipconfig\n","%cp /content/De-Fake/blipmodels/blipconfig/med_config.json /home/sha/stable-diffusion/blipmodels/blipconfig/med_config.json\n","%cd /content/De-Fake/blipmodels/blipconfig"],"metadata":{"id":"61FXD51U1Q3w","executionInfo":{"status":"ok","timestamp":1738704052054,"user_tz":300,"elapsed":263,"user":{"displayName":"Rohan Wagh","userId":"06660321697866433484"}}},"execution_count":14,"outputs":[]},{"cell_type":"code","source":["blip_url = 'https://storage.googleapis.com/sfr-vision-language-research/BLIP/models/model_base_capfilt_large.pth'\n","\n","blip = blip_decoder(pretrained=blip_url, image_size=image_size, vit='base')\n","blip.eval()\n","blip = blip.to(device)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"cZTRyzp58h1B","executionInfo":{"status":"ok","timestamp":1738706602437,"user_tz":300,"elapsed":8902,"user":{"displayName":"Rohan Wagh","userId":"06660321697866433484"}},"outputId":"d68aea2c-e09b-4752-934a-aa959fe60098"},"execution_count":6,"outputs":[{"output_type":"stream","name":"stderr","text":["BertLMHeadModel has generative capabilities, as `prepare_inputs_for_generation` is explicitly overwritten. However, it doesn't directly inherit from `GenerationMixin`. From 👉v4.50👈 onwards, `PreTrainedModel` will NOT inherit from `GenerationMixin`, and this model will lose the ability to call `generate` and other related functions.\n","  - If you're using `trust_remote_code=True`, you can get rid of this warning by loading the model with an auto class. See https://huggingface.co/docs/transformers/en/model_doc/auto#auto-classes\n","  - If you are the owner of the model architecture code, please modify your model class such that it inherits from `GenerationMixin` (after `PreTrainedModel`, otherwise you'll get an exception).\n","  - If you are not the owner of the model architecture class, please contact the model code owner to update it.\n"]},{"output_type":"stream","name":"stdout","text":["load checkpoint from https://storage.googleapis.com/sfr-vision-language-research/BLIP/models/model_base_capfilt_large.pth\n"]}]},{"cell_type":"code","source":[],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"0Ubuyiw3AJYS","executionInfo":{"status":"ok","timestamp":1738704299424,"user_tz":300,"elapsed":254,"user":{"displayName":"Rohan Wagh","userId":"06660321697866433484"}},"outputId":"0287b3b3-7b4e-401a-f38d-1d44a63f1980"},"execution_count":21,"outputs":[{"output_type":"stream","name":"stdout","text":["/content/De-Fake\n"]}]},{"cell_type":"markdown","source":["# TEST"],"metadata":{"id":"KMrNd1FTCTSB"}},{"cell_type":"code","source":["def test_image(image_path):\n","\n","  img = Image.open(image_path).convert('RGB')\n","  tform = transforms.Compose(\n","      [\n","          transforms.Resize(224),\n","          transforms.CenterCrop(224),\n","          transforms.ToTensor(),\n","      ]\n","  )\n","  img = tform(img)\n","  img = img.unsqueeze(0).to(\"cuda\")\n","\n","  caption = blip.generate(img, sample=False, num_beams=3, max_length=60, min_length=5)\n","  text = clip.tokenize(list(caption)).to(device)\n","\n","  model = torch.load(\"finetune_clip.pt\").to(device)\n","\n","  linear = NeuralNet(1024,[512,256],2).to(device)\n","  linear = torch.load('clip_linear.pt')\n","\n","\n","  image = preprocess_image(image_path,image_size).unsqueeze(0).to(device)\n","\n","  with torch.no_grad():\n","      image_features = model.encode_image(image)\n","      text_features = model.encode_text(text)\n","\n","      emb = torch.cat((image_features, text_features),1)\n","      output = linear(emb.float())\n","      predict = output.argmax(1)\n","      predict = predict.cpu().numpy()\n","\n","  return predict\n"],"metadata":{"id":"wL-lBwzfCVR-","executionInfo":{"status":"ok","timestamp":1738706608586,"user_tz":300,"elapsed":357,"user":{"displayName":"Rohan Wagh","userId":"06660321697866433484"}}},"execution_count":7,"outputs":[]},{"cell_type":"code","source":["print(blip._modules.keys())\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"uZ4SLeQm6QTe","executionInfo":{"status":"ok","timestamp":1738705777032,"user_tz":300,"elapsed":271,"user":{"displayName":"Rohan Wagh","userId":"06660321697866433484"}},"outputId":"d25bb83e-3dc9-480e-e390-c9741b7550dd"},"execution_count":52,"outputs":[{"output_type":"stream","name":"stdout","text":["dict_keys(['visual_encoder', 'text_decoder'])\n"]}]},{"cell_type":"code","source":["test_image('/content/data/deepfakeface/real/test/dfface_test0.jpg')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":287},"id":"sSi8f_6eDCDD","executionInfo":{"status":"error","timestamp":1738707196238,"user_tz":300,"elapsed":297,"user":{"displayName":"Rohan Wagh","userId":"06660321697866433484"}},"outputId":"811b66f1-9d03-4237-d43a-59b5019956a2"},"execution_count":12,"outputs":[{"output_type":"error","ename":"RuntimeError","evalue":"The size of tensor a (3) must match the size of tensor b (9) at non-singleton dimension 0","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)","\u001b[0;32m<ipython-input-12-efb2fc12ea35>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtest_image\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/data/deepfakeface/real/test/dfface_test0.jpg'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m<ipython-input-7-6fcefa1b90b9>\u001b[0m in \u001b[0;36mtest_image\u001b[0;34m(image_path)\u001b[0m\n\u001b[1;32m     12\u001b[0m   \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munsqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"cuda\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m   \u001b[0mcaption\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mblip\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgenerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_beams\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_length\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m60\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmin_length\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m   \u001b[0mtext\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclip\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtokenize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcaption\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/content/De-Fake/blipmodels/blip.py\u001b[0m in \u001b[0;36mgenerate\u001b[0;34m(self, image, sample, num_beams, max_length, min_length, top_p, repetition_penalty)\u001b[0m\n\u001b[1;32m    154\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    155\u001b[0m             \u001b[0;31m#beam search\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 156\u001b[0;31m             outputs = self.text_decoder.generate(input_ids=input_ids,\n\u001b[0m\u001b[1;32m    157\u001b[0m                                                   \u001b[0mmax_length\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_length\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    158\u001b[0m                                                   \u001b[0mmin_length\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmin_length\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/utils/_contextlib.py\u001b[0m in \u001b[0;36mdecorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    114\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    115\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mctx_factory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 116\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    117\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    118\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/transformers/generation/utils.py\u001b[0m in \u001b[0;36mgenerate\u001b[0;34m(self, inputs, generation_config, logits_processor, stopping_criteria, prefix_allowed_tokens_fn, synced_gpus, assistant_model, streamer, negative_prompt_ids, negative_prompt_attention_mask, **kwargs)\u001b[0m\n\u001b[1;32m   2281\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2282\u001b[0m             \u001b[0;31m# 13. run beam sample\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2283\u001b[0;31m             result = self._beam_search(\n\u001b[0m\u001b[1;32m   2284\u001b[0m                 \u001b[0minput_ids\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2285\u001b[0m                 \u001b[0mbeam_scorer\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/transformers/generation/utils.py\u001b[0m in \u001b[0;36m_beam_search\u001b[0;34m(self, input_ids, beam_scorer, logits_processor, stopping_criteria, generation_config, synced_gpus, **model_kwargs)\u001b[0m\n\u001b[1;32m   3501\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3502\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# Unchanged original behavior\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3503\u001b[0;31m                 \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mmodel_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3504\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3505\u001b[0m             \u001b[0;31m# synced_gpus: don't waste resources running the code we don't need; kwargs must be updated before skipping\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1735\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1736\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1737\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1745\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1746\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1748\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1749\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/content/De-Fake/blipmodels/med.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, attention_mask, position_ids, head_mask, inputs_embeds, encoder_hidden_states, encoder_attention_mask, labels, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict, return_logits, is_decoder, reduction, mode)\u001b[0m\n\u001b[1;32m    884\u001b[0m         \"\"\"\n\u001b[1;32m    885\u001b[0m         \u001b[0mreturn_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mreturn_dict\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mreturn_dict\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muse_return_dict\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 886\u001b[0;31m         \u001b[0;32mif\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    887\u001b[0m             \u001b[0muse_cache\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1735\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1736\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1737\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1745\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1746\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1748\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1749\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/content/De-Fake/blipmodels/med.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, attention_mask, position_ids, head_mask, inputs_embeds, encoder_embeds, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict, is_decoder, mode)\u001b[0m\n\u001b[1;32m    779\u001b[0m                 \u001b[0mpast_key_values_length\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpast_key_values_length\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    780\u001b[0m             )\n\u001b[0;32m--> 781\u001b[0;31m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    782\u001b[0m             \u001b[0membedding_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mencoder_embeds\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    783\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1735\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1736\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1737\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1745\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1746\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1748\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1749\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/content/De-Fake/blipmodels/med.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict, mode)\u001b[0m\n\u001b[1;32m    443\u001b[0m                     \u001b[0mencoder_hidden_states\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    444\u001b[0m                     \u001b[0mencoder_attention_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 445\u001b[0;31m                     \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    446\u001b[0m                 )\n\u001b[1;32m    447\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1735\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1736\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1737\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1745\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1746\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1748\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1749\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/content/De-Fake/blipmodels/med.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_value, output_attentions, mode)\u001b[0m\n\u001b[1;32m    359\u001b[0m         \u001b[0mpresent_key_value\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself_attention_outputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    360\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 361\u001b[0;31m         \u001b[0;32mif\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0;34m'multimodal'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    362\u001b[0m             \u001b[0;32massert\u001b[0m \u001b[0mencoder_hidden_states\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"encoder_hidden_states must be given for cross-attention layers\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    363\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1735\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1736\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1737\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1745\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1746\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1748\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1749\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/content/De-Fake/blipmodels/med.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_value, output_attentions)\u001b[0m\n\u001b[1;32m    275\u001b[0m         \u001b[0mencoder_hidden_states\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    276\u001b[0m         \u001b[0mencoder_attention_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 277\u001b[0;31m         \u001b[0mpast_key_value\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    278\u001b[0m         \u001b[0moutput_attentions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    279\u001b[0m     ):\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1735\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1736\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1737\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1745\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1746\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1748\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1749\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/content/De-Fake/blipmodels/med.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_value, output_attentions)\u001b[0m\n\u001b[1;32m    176\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    177\u001b[0m         \u001b[0mquery_layer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mquery_layer\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0mmin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mquery_layer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey_layer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 178\u001b[0;31m         \u001b[0mkey_layer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkey_layer\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0mmin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mquery_layer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey_layer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    179\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    180\u001b[0m         \u001b[0;31m# Take the dot product between \"query\" and \"key\" to get the raw attention scores.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mRuntimeError\u001b[0m: The size of tensor a (3) must match the size of tensor b (9) at non-singleton dimension 0"]}]},{"cell_type":"code","source":["path = 'data/deepfakeface/real/test/'\n","num_images = 1500 # 1500 for test datasets, 2500 for train datasets\n","\n","files = os.listdir(path)\n","\n","defake_preds = np.zeros((num_images,))\n","defake_file_num = np.zeros((num_images,))\n","defake_actual = np.zeros((num_images,))\n","\n","for i in range(len(files)):\n","  prediction = test_image(path + files[i])\n","  # Convert to 0 (real) and 1 (deepfake)\n","  defake_preds[i] = 1 if prediction < 0.5 else 0\n","  file_num = files[i].split('.')[0][11:] # Change depending on test or train\n","  defake_file_num[i] = int(file_num)\n","\n","# Save image file numbers and predictions to .npz file\n","np.savez('defake_dff_test_real', mesonet_preds=defake_preds, mesonet_actual=defake_actual, mesonet_file_num=defake_file_num)"],"metadata":{"id":"9xONKYCagt4P"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# EVALS"],"metadata":{"id":"iyZflV_PhtET"}},{"cell_type":"code","source":["from sklearn.metrics import average_precision_score, accuracy_score, precision_score, recall_score, f1_score\n","import matplotlib.pyplot as plt\n","\n","real_data = np.load(\"defake_dff_test_real.npz\")\n","df_data = np.load(\"defake_dff_test_df.npz\")\n","\n","preds = np.concatenate((real_data[\"defake_preds\"], df_data[\"defake_preds\"]))\n","actual = np.concatenate((real_data[\"defake_actual\"], df_data[\"defake_actual\"]))\n","\n","print(accuracy_score(actual, preds))\n","print(precision_score(actual, preds))\n","print(recall_score(actual, preds))\n","print(f1_score(actual, preds))\n","print(average_precision_score(actual, preds))\n","\n","\n","real_data.close()\n","df_data.close()"],"metadata":{"id":"N3O-yDIQhnmb"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from sklearn.metrics import average_precision_score, accuracy_score, precision_score, recall_score, f1_score\n","\n","data = np.load(\"defake_dff_test_real.npz\")\n","print(accuracy_score(data[\"defake_actual\"], data[\"defake_preds\"]))\n","print(np.unique(data[\"defake_file_num\"]))\n","data.close()"],"metadata":{"id":"whcFKUXrhvfH"},"execution_count":null,"outputs":[]}]}